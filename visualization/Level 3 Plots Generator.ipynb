{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1000)\n",
    "random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>ZHVIPerSqft_AllHomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-04-30</td>\n",
       "      <td>10001</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-04-30</td>\n",
       "      <td>10003</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-04-30</td>\n",
       "      <td>1003</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-04-30</td>\n",
       "      <td>1009</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-04-30</td>\n",
       "      <td>1017</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  RegionName  ZHVIPerSqft_AllHomes\n",
       "0 1996-04-30       10001                  58.0\n",
       "1 1996-04-30       10003                  76.0\n",
       "2 1996-04-30        1003                  62.0\n",
       "3 1996-04-30        1009                  44.0\n",
       "4 1996-04-30        1017                  49.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_state_abbrev = {'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', \n",
    "                   'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA', \n",
    "                   'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', \n",
    "                   'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', \n",
    "                   'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT',\n",
    "                   'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', \n",
    "                   'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', \n",
    "                   'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n",
    "                   'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', \n",
    "                   'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'}\n",
    "\n",
    "county_cross = pd.read_csv(\"data/CountyCrossWalk_Zillow.csv\")\n",
    "county_data = pd.read_csv(\"data/County_time_series.csv\", parse_dates=['Date'])\n",
    "county_data = county_data[['Date', 'RegionName', 'ZHVIPerSqft_AllHomes']].dropna().reset_index(drop=True)\n",
    "\n",
    "county_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_county(FIPS):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import random\n",
    "    import plotly\n",
    "    import plotly.offline as py\n",
    "    import plotly.tools as tls\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.tools as tls\n",
    "    import plotly.figure_factory as ff\n",
    "    import numpy as np\n",
    "    import random\n",
    "    np.random.seed(1000)\n",
    "    random.seed(1000)\n",
    "    import keras\n",
    "    keras.backend.clear_session()\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import os\n",
    "\n",
    "    print(FIPS)\n",
    "    statename = county_cross[county_cross['FIPS']== FIPS]['StateName'].values[0]\n",
    "    d = county_data[county_data['RegionName'] == FIPS].reset_index(drop=True)\n",
    "    ma = d['ZHVIPerSqft_AllHomes'].max()\n",
    "    mi = d['ZHVIPerSqft_AllHomes'].min()\n",
    "    d['ZHVIPerSqft_AllHomes'] = (d['ZHVIPerSqft_AllHomes']-mi)/(ma-mi)\n",
    "\n",
    "    def create_dataset(dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back):\n",
    "            a = dataset[i:(i+look_back)]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    lookback = 2\n",
    "    trainX, trainY = create_dataset(d['ZHVIPerSqft_AllHomes'].values, lookback)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5, input_shape=trainX[0].shape))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=False)\n",
    "    pred = model.predict(trainX).flatten()\n",
    "    x = trainX[-1]\n",
    "    y = []\n",
    "    for i in range(24):\n",
    "        train = np.array([x])\n",
    "        pred = model.predict(train).flatten()\n",
    "        y.append(pred[0]*(ma-mi) + mi)\n",
    "        xt = list(x[0])\n",
    "        xt = xt[1:] + [pred[0]]\n",
    "        x = [xt]\n",
    "    y = list(model.predict(trainX).flatten()*(ma-mi)+mi)+y\n",
    "    previous = ['2017-01-31', '2017-02-28', '2017-03-30', '2017-04-30', '2017-05-31', '2017-06-30',\n",
    "                '2017-07-31', '2017-08-31', '2017-09-30', '2017-10-31', '2017-11-30', '2017-12-31']\n",
    "    new = ['2018-01-31 00:00:00', '2018-02-28 00:00:00', '2018-03-31 00:00:00', '2018-04-30 00:00:00', '2018-05-31 00:00:00', '2018-06-30 00:00:00', '2018-07-31 00:00:00', '2018-08-31 00:00:00', '2018-09-30 00:00:00', '2018-10-31 00:00:00', '2018-11-30 00:00:00', '2018-12-31 00:00:00',\n",
    "           '2019-01-31 00:00:00', '2019-02-28 00:00:00', '2019-03-31 00:00:00', '2019-04-30 00:00:00', '2019-05-31 00:00:00', '2019-06-30 00:00:00', '2019-07-31 00:00:00', '2019-08-31 00:00:00', '2019-09-30 00:00:00', '2019-10-31 00:00:00', '2019-11-30 00:00:00', '2019-12-31 00:00:00']\n",
    "    dates = previous[-lookback:] + new[:-lookback]\n",
    "\n",
    "    d['ZHVIPerSqft_AllHomes'] = (d['ZHVIPerSqft_AllHomes']*(ma-mi))+mi\n",
    "    true = d.iloc[:-lookback]\n",
    "    pred = pd.DataFrame(columns=true.columns)\n",
    "    pred['Date'] = list(d['Date'].values[:-lookback])+dates\n",
    "    pred['ZHVIPerSqft_AllHomes'] = y\n",
    "    pred['RegionName'] = FIPS\n",
    "    dirs = os.listdir('UI/plots/states')\n",
    "    a = us_state_abbrev[statename]\n",
    "    if a not in dirs:\n",
    "        os.mkdir('UI/plots/states/'+a)\n",
    "    pred.to_csv('UI/plots/states/'+a+'/'+str(FIPS)+'.csv', index=False)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(processes=36)\n",
    "args = list(county_data['RegionName'].unique())\n",
    "for i in pool.map(plot_county, args, chunksize=int(len(args)/36)+1):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdh_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
